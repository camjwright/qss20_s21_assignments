{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 2: part one\n",
    "\n",
    "Total points: 20\n",
    "\n",
    "Fraction of problem set two points: 25\\%\n",
    "\n",
    "**Concepts**: here, you're going to start using the SIP H-2A employer jobs and debarment data to practice exact matching,  regex, and fuzzy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import recordlinkage\n",
    "\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regex and exact matching (8 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Load data on debarments and job postings (0 points)\n",
    "\n",
    "Load the following datasets stored in `pset2_part1_inputdata`\n",
    "    \n",
    "- Historical H2A debarments (debar.csv); call this `debar`\n",
    "- Q1 2021 H2A job postings (jobs.csv); call this `jobs`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "debar = pd.read_csv('../../debar.csv')\n",
    "jobs = pd.read_csv('../../jobs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Try exact merge on business name  (2 points)\n",
    "\n",
    "- Use the `EMPLOYER_NAME` field of jobs\n",
    "- Use the `Name` field of debar\n",
    "\n",
    "A. Use pd.merge with an inner join on those fields to see whether there are any exact matches. \n",
    "\n",
    "B. If there are matches, print the name in each dataset, date range of debarment (`Start date` and `End date` in `debar`) and location from each data (`City, State` in `debar` and `EMPLOYER_CITY` and `EMPLOYER_STATE` in `jobs`)\n",
    "\n",
    "**Resources**:\n",
    "    - Slides 17-19 here: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/slides/qss20_s21_class4.pdf \n",
    "    - Code here: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/03_merging_session1.ipynb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Rafael Barajas\n",
      "Name: Name, dtype: object 0    Rafael Barajas\n",
      "Name: EMPLOYER_NAME, dtype: object 0    9/23/2016\n",
      "Name: Start date, dtype: object 0    9/22/2017\n",
      "Name: End date, dtype: object 0    Sebring, Florida\n",
      "Name: City, State, dtype: object 0    Port St. Lucie\n",
      "Name: EMPLOYER_CITY, dtype: object 0    FL\n",
      "Name: EMPLOYER_STATE, dtype: object\n"
     ]
    }
   ],
   "source": [
    "debarMergejobs = pd.merge(debar, jobs, left_on = \"Name\", right_on = \"EMPLOYER_NAME\")\n",
    "print(debarMergejobs['Name'], debarMergejobs['EMPLOYER_NAME'], debarMergejobs['Start date'], debarMergejobs['End date'], debarMergejobs['City, State'], debarMergejobs['EMPLOYER_CITY'], debarMergejobs['EMPLOYER_STATE'])\n",
    "#I know this comes out not very pretty but it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Targeted regex\n",
    "\n",
    "You want to see if you can increase the exact match rate with some basic cleaning of each \n",
    "of the name fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Converting to upper (2 points)\n",
    "\n",
    "A. Convert the names `EMPLOYER_NAME` and `Name` to uppercase using list comprehension rather than df.varname.str.upper()\n",
    "\n",
    "B. Print a random sample of 15 values of each result\n",
    "\n",
    "C. Assign them back to the original data, writing over the original columns\n",
    "\n",
    "**Resources**:\n",
    "    - `new_colnames` line of code here for example of list comprehension: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/04_basicregex_formerging.ipynb\n",
    "    - Sampling from a list without replacement using the `random` module: https://note.nkmk.me/en/python-random-choice-sample-choices/ \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BLUEPOINTPRODUCELLC',\n",
       " 'JACKIEPARKBURRISQUEENSINC',\n",
       " 'COLDSTREAMFISHERIESINC',\n",
       " 'COMMERCIALNURSERYCOMPANYINC',\n",
       " 'SANDYWEBSTER',\n",
       " 'VIRGINIAAGRICULTURALGROWERSASSOCIATIONINC',\n",
       " 'VPCPRODUCELLC',\n",
       " 'KEEVENBROSINC',\n",
       " 'MAGRAINLLC',\n",
       " 'BARCINC',\n",
       " 'MARKZAUNBRECHER',\n",
       " 'COUNTRYLIFEFARMLLP',\n",
       " 'WESTERNRANGEASSOCIATION',\n",
       " 'MATHESHORSECATTLECOMPANYLLC',\n",
       " 'WASHINGTONSPRINGSAG']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['EVRANCHLLP',\n",
       " 'TRAVISANDTARALAMBOURN',\n",
       " 'MACKYANDBRADFARMS',\n",
       " 'ANNABELLALANDCATTLE',\n",
       " 'REIMERSINC',\n",
       " 'CADDOCREEKRANCHDBAPARADISERANCH',\n",
       " 'JAVIERXISTOZAPATA',\n",
       " 'GERONIMOSHEEPCO',\n",
       " 'DEALFAMILYFARM',\n",
       " 'YOLANDACHAVEZ',\n",
       " 'ANTONFERTILIZERINC',\n",
       " 'JOHNRCOOK',\n",
       " 'ROSALVAGARCIA',\n",
       " 'FIRSTAMERICANHOLDINGS',\n",
       " 'AGECYILLC']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_colnamesJ = [re.sub(\"[^A-Za-z0-9]+\", \"\", col.upper()) for col in jobs['EMPLOYER_NAME']]\n",
    "new_colnamesD = [re.sub(\"[^A-Za-z0-9]+\", \"\", col.upper()) for col in debar['Name']]\n",
    "UpperJ = random.sample(new_colnamesJ, 15)\n",
    "UpperD = random.sample(new_colnamesD, 15)\n",
    "UpperJ\n",
    "UpperD\n",
    "jobs['EMPLOYER_NAME'] = new_colnamesJ\n",
    "debar['Name'] = new_colnamesD\n",
    "\n",
    "## rj note - close! you'll notice though that it removes stuff\n",
    "## like spaces from the strings which might affect later matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Cleaning up punctuation (4 points)\n",
    "\n",
    "You notice that INC, CO, and LLC are sometimes followed by a . but sometimes not\n",
    "\n",
    "A. For each dataset, write a regex pattern to remove the . but only if it's preceded by INC, LLC, or CO \n",
    "\n",
    "Make sure LLC, INC, CO remain part of the string but just without the dot\n",
    "\n",
    "B. Test the pattern on the positive and negative example and print the result. The first positive example should return `CISCO PRODUCE INC`; the second positive example should return `AVOYELLES HONEY CO, LLC` the negative example should return `E.V. RANCH LLP` (so leave the dots between E.V. in)\n",
    "\n",
    "C. Execute on (1) Name in `debar` (can just write over the col) and (3) EMPLOYER_NAME  in `jobs`, making sure to use the uppercase versions of the variables\n",
    "\n",
    "**Hint**: https://stackoverflow.com/questions/7191209/python-re-sub-replace-with-matched-content\n",
    "\n",
    "**Resources**:\n",
    "    - Regex slides are 22-40: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/slides/qss20_s21_class4.pdf \n",
    "    - Regex code: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/04_basicregex_formerging.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CISCO PRODUCE INC'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'AVOYELLES HONEY CO, LLC'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'E.V. RANCH LLP'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_example_1 = \"CISCO PRODUCE INC.\"\n",
    "pos_example_2 = \"AVOYELLES HONEY CO., LLC\"\n",
    "neg_example = \"E.V. RANCH LLP\"\n",
    "\n",
    "dot_pattern = r'(LLC|INC|CO)\\.'\n",
    "re.sub(dot_pattern, r'\\1', pos_example_1)\n",
    "re.sub(dot_pattern, r'\\1', pos_example_2)\n",
    "re.sub(dot_pattern, r'\\1', neg_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91    AVOYELLESHONEYCOLLC\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "91    AVOYELLESHONEYCOLLC\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## rj- added some checks pre and post\n",
    "## see that the re.sub isnt actually doing anything\n",
    "## since earlier step removed all punctuation so already\n",
    "## removed . after everything- no further deduction since\n",
    "## worked on test patterns\n",
    "debar.Name[debar.Name.str.contains(\"AVOYELLES\")]\n",
    "debar['Name'] = [re.sub(dot_pattern, r'\\1', name) for name in debar['Name']]\n",
    "jobs['EMPLOYER_NAME'] = [re.sub(dot_pattern, r'\\1', name) for name in jobs['EMPLOYER_NAME']]\n",
    "\n",
    "debar.Name[debar.Name.str.contains(\"AVOYELLES\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 OPTIONAL extra credit - regex to separate companies from individuals (2 points)\n",
    "\n",
    "You notice some employers in `debar` have both the name of the company and the name of individual, e.g.:\n",
    "    \n",
    "COUNTY FAIR FARM (COMPANY) AND ANDREW WILLIAMSON (INDIVIDUAL)*\n",
    "\n",
    "Use the uppercase/cleaned version of the Name in `debar`\n",
    "\n",
    "A. Write a regex pattern that does the following:\n",
    "    - Captures the pattern that occurs before COMPANY if (COMPANY) is in string-- so in above, extracts COUNTY FAIR FARM \n",
    "    - Captures the pattern that occurs before INDIVIDUAL if (INDIVIDUAL) is also in string -- so in above, extracts ANDREW WILLIAMSON (so omit the and)\n",
    "    \n",
    "B. Test the pattern on `pos_example` and `neg_example`-- make sure former returns a list (if using find.all) or match object (if using re.search) with the company name and individual name separated out; make sure latter returns empty\n",
    "    \n",
    "C. Iterate over the cleaned `Name` column in debar and execute the regex. Use it to create two new columns in debar:\n",
    "    - A column for company (full Name string if left as is; pattern before COMPANY if one extracted)\n",
    "    - A column for individual (full Name string if left as is; pattern before INDIVIDUAL if one extracted)\n",
    "    \n",
    "D. Print those columns for the rows containing the negative example and positive example\n",
    "\n",
    "**Hint**: for step A, you can either use re.search, re.match, or re.findall; don't worry about matching B&R Harvesting and Paul Cruz (Individual)\n",
    "\n",
    "For step C, you probably want to use a loop or function that uses if else to do different things if a match is found or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_example = \"COUNTY FAIR FARM (COMPANY) AND ANDREW WILLIAMSON (INDIVIDUAL)*\"\n",
    "neg_example = \"CISCO PRODUCE INC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Fuzzy matching to match debarments to jobs (12 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Preprocessing location (2 points)\n",
    "\n",
    "You want to block on state but notice that states in `debar` have a mix of two digit codes and full state names (e.g., GA versus Georgia) while states in `jobs` are all two-digit codes\n",
    "\n",
    "A. Run the code below to load the `states` crosswalk. Use that crosswalk to create a field in `debar` that has the two-digit state abbreviation for all locations (hint: you may need to first split the string on the \", \" or use str.replace to extract the state)\n",
    "\n",
    "B. Use an `assert` statement to check that all the states in `debar` are two-digits after the cleaning\n",
    "\n",
    "**Notes**: you can filter out states that are NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GA    18\n",
       "TX    18\n",
       "KS    10\n",
       "FL    10\n",
       "UT     6\n",
       "ND     6\n",
       "SD     5\n",
       "KY     5\n",
       "CA     4\n",
       "NY     3\n",
       "LA     3\n",
       "MA     3\n",
       "AR     3\n",
       "CO     3\n",
       "OK     2\n",
       "ID     2\n",
       "MT     2\n",
       "MD     1\n",
       "TN     1\n",
       "VT     1\n",
       "NC     1\n",
       "ME     1\n",
       "IL     1\n",
       "AK     1\n",
       "SC     1\n",
       "Name: State, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## code to load state crosswalk\n",
    "## source- https://towardsdatascience.com/state-name-to-state-abbreviation-crosswalks-6936250976c\n",
    "cw_location = 'http://app02.clerk.org/menu/ccis/Help/CCIS%20Codes/'\n",
    "cw_filename = 'state_codes.html'\n",
    "states = pd.read_html(cw_location + cw_filename)[0]\n",
    "\n",
    "newdf = debar['City, State'].str.split(',', expand = True)\n",
    "newdf[1] = newdf[1].str.strip()\n",
    "newdf = newdf.merge(right = states, how = 'left', left_on = newdf[1], right_on = states.Description)\n",
    "newdf['Code'] = np.where(newdf.Code.isna(), newdf[1], newdf.Code)\n",
    "debar['City'] = newdf[0]\n",
    "debar['State'] = newdf['Code']\n",
    "debar = debar[debar.State.notna()]\n",
    "assert (debar.State.apply(len)== 2).all(), \"Error\"\n",
    "\n",
    "## rj addition\n",
    "debar.State.value_counts(dropna = False)\n",
    "\n",
    "## good job!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 step by step fuzzy matching (4 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Write fuzzy matching code (don't yet put inside a user-defined function) that:\n",
    "\n",
    "- Blocks on two-digit state code\n",
    "- Finds matches based on similarity between the employer name (`Name`) in `debar` (uppercase and cleaned) and `EMPLOYER_NAME` in `jobs` (uppercase and cleaned). You can choose which distance metric and threshold to use (feel free to set a threshold low enough to get some matches even if that leads to some false positives).\n",
    "\n",
    "For the steps after compute, just take any match with non-zero value rather than using a classifier (so skip the k-means or e-m step in the example code)\n",
    "\n",
    "B. Print the matches and comment on examples of ones that seem like true positives and ones that seem like false matches\n",
    "\n",
    "**Resources**:\n",
    "\n",
    "- Solutions code here: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/05_merging_session2_activitysolutions.ipynb \n",
    "- Example code here: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/05_merging_session2_codeexample.ipynb\n",
    "\n",
    "\n",
    "**Hint**: you may need to deduplicate multiple records in the datasets for the recordlinkage package to work. See drop_duplicates within pandas and subset command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 write a fuzzy matching function (6 points)\n",
    "\n",
    "You want to see how the matches change if you add the town and not only state as a field and also want to automate the process of matching a bit to try different distance thresholds.\n",
    "\n",
    "A. Extract the City from the `City, State` column of debar\n",
    "\n",
    "B. Convert that new `city` column to uppercase and convert the `EMPLOYER_CITY` column in jobs to uppercase\n",
    "\n",
    "C. Write a function surrounding the code in `recordlinkage` (so you don't need to recode the package from scratch) that (1) takes in each dataset, (2) blocks on two-digit state, and (3) fuzzy matches on employer name and employer city\n",
    "\n",
    "D. Execute the function with a couple different string distance thresholds and print the results of each\n",
    "\n",
    "5 out of 6 points: function takes arguments for input datasets, varname to block on, two varnames to fuzzy match on, string distance function, and string distance threshold\n",
    "    \n",
    "6 out of 6: above but function is also general enough that it takes a variable # of strings to match on--- so should work if you either execute just using employer name or also work if you execute using employer name and employer city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job on the ones completed! Guessing the final two were just running out of time but next time definitely stop by office hours if the example code is confusing since largely just copying/pasting from resources I linked to!\n",
    "\n",
    "See github for full points breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw total: 11.5\n",
    "    \n",
    "Adjusted total: 14.15\n",
    "    \n",
    "Percent: 57.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
